EXAMINATIONS OF THE HONG KONG STATISTICAL SOCIETY
GRADUATE DIPLOMA, 2014
MODULE 1 : Probability distributions
Time allowed: Three hours
Candidates should answer FIVE questions.
All questions carry equal marks.
The number of marks allotted for each part-question is shown in brackets.
Graph paper and Official tables are provided.
Candidates may use calculators in accordance with the regulations published in
the Society's "Guide to Examinations" (document Ex1).
The notation log denotes logarithm to base e.
Logarithms to any other base are explicitly identified, e.g. log 10 .
Note also that
( nr ) is the same as
n
C r .
1
This examination paper consists of 8 printed pages.
This front cover is page 1.
Question 1 starts on page 2.
There are 8 questions altogether in the paper.
© RSS 2014
GD Module 1 20141.
(i)
Let X be a continuous random variable and A an event with probability θ ,
where 0 < θ < 1. Conditional on A, X has cumulative distribution function
F 1 ( x ) and expectation μ 1 while, conditional on A′ (the complement of A), X
has cumulative distribution function F 2 ( x ) and expectation μ 2 . Justify the
expression
F =
( x ) θ F 1 ( x ) + (1 − θ ) F 2 ( x )
for the cumulative distribution function F(x) of X and hence deduce that
E ( X ) = θμ 1 + (1 − θ ) μ 2 .
(5)
Small chocolate biscuits of a certain brand are sold in packets of 6 with a nominal
weight of 25 g. The weight (g) of an individual biscuit is a N(4.5, 0.25) random
variable, and the weights of different biscuits are independent.
(ii)
Find the probability that, in total, 6 of these biscuits weigh less than 25 g.
(5)
(iii) When 6 biscuits are put together to form a packet, if their total weight is found
to be less than 25 g then a seventh biscuit is added to the packet. Find the mean
weight of a packet of biscuits.
(4)
(iv) If it is simply known that the weight of an individual biscuit is a N(4.5, σ 2 )
random variable, for what values of σ is the probability less than 0.01 that
6 biscuits weigh less than 25 g?
(6)
22.
The continuous random variable X has a probability density function, f (x), that is
symmetrical about x = 0, i.e. f (–x) = f (x) for all x, and all moments of X exist.
(i)
Use integration to prove that the median of X is 0.
(4)
(ii)
Use integration to prove that E(X) = 0.
(3)
Let Y = X 2 .
(iii) Show that E(XY) = 0. Deduce that X and Y are uncorrelated. Are X and Y
independent? Justify your answer.
(7)
(iv) Show that Y has probability density function g(y) given by
=
g ( y )
1
f ( y ) ,
y
y ≥ 0 .
(6)
3.
The continuous random variables X and Y have joint probability density function
=
f ( x , y )
1 − x
e ,
x
0 < y < x .
(i) Show that X has an exponential distribution. Hence show that, conditional on
X = x, Y has the uniform distribution on the interval (0, x).
(7)
(ii) Show that, for non-negative integers m and n,
E ( X m Y n ) =
( m + n )!
.
n + 1
(5)
(iii)
Use the result proved in part (ii) to obtain E(X), Var(X), E(Y) and Var(Y). Find
and interpret the value of the correlation between X and Y.
(8)
[You may use without proof the result that, for any non-negative integer r,
∞
∫ 0 u e
r − u
du = r ! ]
34.
(a)
(b)
The discrete random variable X 1 takes the value 0 with probability 0.2 and the
value 1 with probability 0.8. The discrete random variable X 2 takes the value 0
with probability 0.4 and the value 1 with probability 0.6. X 1 and X 2 are
correlated and P(X 1 = 1, X 2 = 1) = 0.5.
(i) Produce a table that shows all the values of the joint probability
distribution of (X 1 , X 2 ).
(4)
(ii) Let Y = 2X 1 + X 2 . Using the table of random digits in the Statistical
tables for use in examinations, simulate 10 values from the distribution
of Y. Explain your method carefully.
(6)
(iii) Use the simulated values from part (ii) to obtain 10 simulations from
the joint distribution of (X 1 , X 2 ).
(2)
The following values are a random sample from a uniform distribution on the
range 0 to 1.
0.209
0.363
0.516
0.970
(i) Use these values to generate 4 random variates from the standard
Normal distribution, explaining your method carefully. (Give your
answers to two decimal places.)
(4)
(ii) Use the results of part (i) to generate 4 random variates from the
χ 2 distribution with one degree of freedom.
(2)
(iii) Use the results of part (ii) to generate 1 random variate from the
χ 2 distribution with four degrees of freedom.
(2)
45.
(a)
The continuous random variables X 1 and X 2 jointly have the bivariate Normal
1 2
distribution with expectation (–1 1) T and covariance matrix
.
2 16
(
(i)
)
Find the correlation between X 1 and X 2 .
(2)
(ii)
Let Y 1 = X 1 + X 2 . Write down E(Y 1 ) and Var(Y 1 ).
(3)
(iii)
(b)
Let Y 2 = kX 1 + X 2 where k is a constant. Find the value of k such that
Y 2 is independent of Y 1 .
(5)
Let X 1 , X 2 , ..., X n (n ≥ 3) be independent random variables, each with the
N(0, σ 2 ) distribution for some σ 2 > 0. The random variable Y t is defined by
Y t =
1
( X t
3
+ X t + 1 + X t + 2 ) , t = 1, 2,  , n − 2 .
Find the mean vector and covariance matrix of Y 1 , Y 2 , ..., Y n–2 . What is the
joint distribution of Y 1 , Y 2 , ..., Y n–2 ?
(10)
56.
(i)
The continuous random variable X has the gamma distribution with parameters
α > 0 and θ > 0, so that X has probability density function
f ( x )
=
θ α x α − 1 e − θ x
, x > 0 ,
Γ ( α )
∞
α − 1 − u
where Γ ( α ) is the gamma function defined by Γ ( α ) =
∫ u e du .
0
Show that the moment generating function of X is
=
M X ( t )
( θ − t ) ,
θ
α
Hence show that E ( X ) =
t < θ .
α
α
and Var( X ) = 2 .
θ
θ
(9)
(ii)
The exponential distribution is the special case of the gamma distribution with
α = 1. Let X 1 , X 2 , ..., X n (n ≥ 1) be independent random variables each with
the exponential distribution with parameter θ . Using moment generating
n
functions, show that
and θ .
∑ X i
has the gamma distribution with parameters n
i = 1
(5)
(iii)
State the Central Limit Theorem. Use it, along with the results from parts (i)
and (ii), to prove that the gamma distribution with parameters n and θ can be
approximated by a Normal distribution for large enough n. State clearly the
parameters of this Normal distribution.
(6)
67.
A bag contains m red beads and n – m blue beads (where m ≥ 1 and n – m ≥ 1).
k beads are chosen at random without replacement from all the n beads in the bag.
Let the random variable X i (i = 1, 2, ..., k) take the value 1 if the i th bead chosen is red
and the value 0 if it is blue.
(i)
1) =
For i = 1, 2, ..., k and j = 1, 2, ..., k, where i ≠ j, explain why P ( X =
i
m
n
m ( m − 1)
. Use these results to find the expected value
n ( n − 1)
and variance of X i and to show that the covariance between X i and X j (i ≠ j) is
X =
1) =
and P ( X =
i
j
Cov( X i , X j ) = −
m ( n − m )
.
n 2 ( n − 1)
(13)
(ii)
The random variable S is the total number of red beads removed from the bag.
Use the results derived in part (i) to find the expected value of S and show that
Var(
=
S ) k
( )( )
m
m n − k
.
1 −
n
n n − 1
(7)
8.
A competitor is to shoot at a vertical target, with centre point O. X and Y are,
respectively, the horizontal and vertical displacements (in cm) from O to the point
where a bullet fired by this competitor hits the target. R and Q are defined by
=
X R =
cos Q , Y R sin Q .
Here, R > 0 is the distance (in cm) from O to the point where a bullet hits the target
and Q (in the range 0 to 2π radians) is the angle from the horizontal axis to the ray
through O on which the bullet lies, measuring counter-clockwise.
(i) X and Y are modelled as independent Normal random variables, each with
expected value 0 and standard deviation σ . Find the joint probability density
function of R and Q.
(11)
(ii) Explain how you know that R and Q are independent. Find the marginal
probability density function of R.
(4)
(iii) Find the value k (> 0) such that 50% of the bullets fired by this competitor will
lie within a circle of radius k σ cm centred at O.
(5)
7BLANK PAGE
8
