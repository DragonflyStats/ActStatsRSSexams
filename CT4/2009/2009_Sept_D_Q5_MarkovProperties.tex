\documentclass[a4paper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngpage}

%\usepackage{bigints}
\usepackage{vmargin}

% left top textwidth textheight headheight

% headsep footheight footskip

\setmargins{2.0cm}{2.5cm}{16 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}

\renewcommand{\baselinestretch}{1.3}

\setcounter{MaxMatrixCols}{10}

\begin{document}


5
\begin{enumerate}[(a)]
\item State the Markov property.

A stochastic process X ( t ) operates with state space S .
\item (ii) Prove that if the process has independent increments it satisfies the Markov
property.

\item (iii) (a)
Describe the difference between a Markov chain and a Markov jump
process.
(b)
Explain what is meant by a Markov chain being irreducible.

An actuarial student can see the office lift (elevator) from his desk. The lift has an
indicator which displays on which of the office’s five floors it is at any point in time.
For light relief the student decides to construct a model to predict the movements of
the lift.
\item (iv)
Explain whether it would be appropriate to select a model which is:
(a)
(b)
irreducible
has the Markov property
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
5
\begin{itemize}
\item (i) The Markov property states that the future development of a process can be
predicted from its present state alone without reference to its past history.
\item (ii) Formally, for times s 1  s 2  ...  s n  s  t and for states x 1 , x 2 ,..., x n , x in the
state space S and all subsets A of S, the Markov property can be written
\begin{verbatim}
\[Pr[ X ( t )  A | X ( s 1 )  x 1 , X ( s 2 )  x 2 ,...., X ( s n )  x n , X ( s )  x ]  Pr[ X t  A | X ( s )  x ]
For independent increments we can write
Pr[ X ( t )  A | X ( s 1 )  x 1 , X ( s 2 )  x 2 ,...., X ( s n )  x n , X ( s )  x ]
=Pr[ X ( t )  X ( s )  x  A | X ( s 1 )  x 1 , X ( s 2 )  x 2 ,...., X ( s n )  x n , X ( s )  x ]
=Pr[ X ( t )  X ( s )  x  A | X ( s )  x ]
= Pr[ X ( t )  A | X ( s )  x ]
\end{verbatim}

%%-- Page 6  — %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% — Examiners’ Report
\item (iii)
a. A Markov chain is a stochastic process with the Markov property
which has a discrete time set with a discrete state space. A Markov
jump process is a stochastic process with the Markov property which
has a continuous time set with a discrete state space.
\item b.A Markov chain is irreducible if any state can be reached from any
other state.
\item (iv)

a. A lift could not serve its purpose unless it could return to each of the
floors which it serves. This means an irreducible model would be
appropriate.
\item b.Suppose, for example, the lift is currently at the third floor, with its last
two states being the fourth floor and the fifth floor. In such a case the
lift is more likely to be heading downwards than upwards. So the past
history is likely to provide information on the likely future movement
of the lift, unless the state space is very complicated (involving a
number of past floors as well as the current floor). Therefore a Markov
model is unlikely to be appropriate.
\item This question was generally well answered, apart from section (iv)(b) in which few
candidates spotted the point that the direction of travel of the lift as well as its current
floor will influence its next location.
\end{itemize}
\end{document}
