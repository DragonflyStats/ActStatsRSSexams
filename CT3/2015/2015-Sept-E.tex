\documentclass[a4paper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngpage}
%\usepackage{bigints}
\usepackage{vmargin}

% left top textwidth textheight headheight

% headsep footheight footskip

\setmargins{2.0cm}{2.5cm}{16 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}

\renewcommand{\baselinestretch}{1.3}

\setcounter{MaxMatrixCols}{10}

\begin{document}

\begin{enumerate}
% CT3 S2015–6
% Question 10 
\item The random variables X1, X2, ..., Xn are independent from each other and all follow a
Poisson distribution with parameter $\lambda$.
\begin{enumerate}[(i)]
\item (i) Derive the maximum likelihood estimator of \lambda based on X1, X2, ..., Xn. You
are not required to verify that your answer corresponds to a maximum. 
\item (ii) Derive an expression for an approximate 95\% confidence interval for \lambda under
the situation in part (i), using the Cramer-Rao lower bound. 
Suppose that instead of observing the values of X1, X2, , Xn precisely, we only
observe that for K of these variables we have Xi  0 , while for the remaining
variables we have Xi  0 .
\item (iii) (a) Derive the maximum likelihood estimator of \lambda when only this
information is available. You are not required to verify that your
answer corresponds to a maximum. [6]
(b) Explain why we need to observe at least one variable to be equal to
zero for the estimator in part (iii) (a) to provide a sensible answer. 
\item (iv) State, with reasons, whether you would prefer to use the estimator of \lambda in part
(i) or that in part (iii). 
\end{enumerate}
\end{enumerate}
[Total 17]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Q10 (i) We have
 
1
! !
  n Xi n iXi
i i i i
L e e
X X
  

 
    and
  log   log   i log i !
  i i
l L n X X
 
        
 
 
and   0 / 0 ˆ / i i
i i
dl n X X n X
d
        
  
Subject CT3 (Probability and Mathematical Statistics Core Technical) – September 2015 – %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Page 10
(ii) Using asymptotic properties of the maximum likelihood estimator (MLE)
ˆ ~ N , CRlb approximately
with
   
2
2 2
2
1 1
i / i ( i ) i
CRlb
d E X E X n E l
d
 
     
         
 
Therefore an approximate 95\% confidence interval is given by ˆ 1.96
n

 
and replacing for the variance: 1.96
ˆ ˆ
n

  , i.e. X 1.96 X
n

[Could also use central limit theorem with normal approximation to Poisson]
(iii) (a) We have Xi  0 with probability e and Xi  0 with probability
1 e
Therefore, likelihood is given as
  1 
K n K L e e

      
l   log L  K  n  K log 1 e 
and
  0   0 ˆ log
1
d l K n K e K
d e n


               
(b) If K = 0 the estimate of $\lambda$ is infinity, so we need K ≥ 1.
(iv) The estimator in part (i) is based on more information, as the exact values of
the data are known, whereas in part (iii) only partial information is available.
Therefore the estimator in part (i) should be more reliable and is preferable.
Parts (i) and (ii) mostly well answered. In part (iii) many candidates did not
use the correct likelihood form. Answers to questions involving the likelihood
function of a model that may not be typical, have also been problematic in
recent sessions and candidates are encouraged to practise more with this
fundamental concept in statistics.

\end{document}


