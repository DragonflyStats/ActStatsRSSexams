\documentclass[a4paper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngpage}

%\usepackage{bigints}
\usepackage{vmargin}

% left top textwidth textheight headheight

% headsep footheight footskip

\setmargins{2.0cm}{2.5cm}{16 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}

\renewcommand{\baselinestretch}{1.3}

\setcounter{MaxMatrixCols}{10}

\begin{document}
\begin{enumerate}

5
Hence verify that the maximum likelihood estimator (MLE) of $\theta$ is the
same as the MME.
[4]
Suggest two ways in which the MLE of $\theta$ can be computed when a particular
data set is given.


Consider a random sample consisting of the random variables X 1 , X 2 ,..., X n with
mean $\mu$ and variance $\sigma^2$ . The variables are independent of each other.
\begin{enumerate}
\item (i)
Show that the sample variance, $S^{2}$ , is an unbiased estimator of the true
variance $\sigma^2$ .\\
\medskip

Now consider in addition that the random sample comes from a normal distribution,
$( n − 1) S^{2}$
in which case it is known that
~ χ n 2 − 1 .
2
\sigma 
\item (ii)
%%---- CT3 S2013–3
(a) Derive the variance of $S^{2}$ in terms of $\sigma$  and $n$.
(b) Comment on the quality of the estimator $S^{2}$ with respect to the sample
size n.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
5
(i)

\[E(S^2)  = E \left[ \frac{}{n \;-\; 1} \right] \;=\; \frac{1}{n \;-\; 1}\left[E(X_{i}^2) \right]  \;-\; \frac{}{n \;-\; 1}\]

and using 
\[E(X^2)  =  var ( X ) - \left[ E ( X ) \right]  \]
%%%%%%%%%%%%%%%%%%%%%%%%%%%

(ii)
(a)

\[E(X^2)  =  var ( X ) - \left[ E ( X ) \right]  \]

\[ E S^{2}  =  = \frac{n}{n-1} \left( \sigma^2 \;+\; \mu^2 \right) \;-\; \frac{n}{n-1} \left( \frac{\sigma^2}{n} \;+\; \mu^2 \right) 

\[ \operatorname{Var} \left[ \frac{ ( n \;-\; 1)S^{2} }{\sigma^2} \right] \;=\; 2( n \;-\; 1)\]

\[ \operatorname{Var}(S^{2}) \;=\; \frac{ 2( n \;-\; 1)\sigma  4}{( n \;-\; 1) 2}  \;=\; \frac{2\sigma^4}{( n \;-\; 1)}  \]

Estimator gets better (more accurate) as n increases, as its variance reduces.
(MSE also gets smaller)
This question was generally well answered. There were a few problems with determining the
expectation of the sample mean in part (i).

\end{document}
