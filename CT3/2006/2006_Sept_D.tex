
\documentclass[a4paper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngpage}

%\usepackage{bigints}
\usepackage{vmargin}

% left top textwidth textheight headheight

% headsep footheight footskip

\setmargins{2.0cm}{2.5cm}{16 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}

\renewcommand{\baselinestretch}{1.3}

\setcounter{MaxMatrixCols}{10}

\begin{document}
\begin{enumerate}


%%--- Question 8
\item Let $X_1$ denote the mean of a random sample of size n from a normal population with
mean
2
1 ,
and variance
and let X 2 denote the mean of a random sample also of
size n from a normal population with the same mean
two samples are independent.
but with variance
2
2 .
The
Define W as the weighted average of the sample means
W
X 1 (1
) X 2
\begin{enumerate}[(i)]
\item (i) Show that W is an unbiased estimator of . [1]
\item (ii) Obtain an expression for the mean square error of W. [2]
\item (iii) Show that the value of
given by
2
2
2
1
2
2
for which W has minimum mean square error is
,
and verify that the optimum corresponds to a minimum.
9
\item 
(iv) Consider the special case when the variances of the two random samples are
equal to a common value 2 . State (do not derive) the maximum likelihood
estimator of calculated from the combined samples, and compare it with the
estimator obtained in (iii).
\end{enumerate}

\item 

\begin{enumerate}[(i)]
\item (i) Show that for continuous random variables X and Y:
\[E[Y] = E[E(Y|X)].\]
\item (ii)
Suppose that a random variable X has a standard normal distribution, and the
conditional distribution of a Poisson random variable Y, given the value of
X = x, has expectation g(x) = x 2 + 1.
Determine $E[Y]$ and $Var[Y]$.
\end{enumerate}
4
\item %%-- Queation 10
Let (X 1 , X 2 ,
, X n ) be a random sample of a gamma(4.5, ) random variable, with
sample mean X .
(i)
(ii)
2
9 n .
\begin{enumerate}[(i)]
\item (a) Using moment generating functions, show that 2 nX ~
\item (b) Construct a 95% confidence interval for , based on X and the result
in (i)(a) above.
\item (c) Evaluate the interval in (i)(b) above in the case for which a random
sample of 10 observations gave a value
x i 21.47
\end{enumerate}
%%%%%%%%%%%%%%
(a) Show that the maximum likelihood estimator of
is given by
4.5
.
X
(b)
Show that the asymptotic standard error of
4.5n
(c)
1/ 2
is estimated by
.
Construct a 95% confidence interval for based on the asymptotic
distribution of , and evaluate this interval in the case for which a
random sample of 100 observations gave a value
x i 225.3.
[9]
[Total 18]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%8
(i)
\begin{eqnarray*}
E ( W ) &=& E ( \alpha X 1 + (1 − \alpha ) X 2 )\\
&=& \alpha E ( X 1 ) + (1 − \alpha ) E ( X 2 ) \\ &=& \alphaμ + (1 − \alpha ) μ \\ &=& μ\\
\end{eqnarray*}

Therefore W is unbiased.
(ii)
MSE(W) = var(W) + {bias(W)} 2
W is unbiased
\begin{eqnarray*} 
MSE(W) &=& var(W)\\
&=& var( \alpha X 1 + (1 − \alpha ) X 2 )\\
&=& \alpha 2 var( X 1 ) + (1 − \alpha ) 2 var( X 2 ) (independent samples)\\
&=& \alpha 2
\end{eqnarray*}


(iii)
\sigma 1 2
\sigma 2
+ (1 − \alpha ) 2 2
n
n
\sigma 2
\sigma 2
d MSE
= 2 \alpha 1 − 2(1 − \alpha ) 2
d \alpha
n
n
d MSE
= 0 ⇒ ( \sigma 1 2 + \sigma 2 2 ) \alpha = \sigma 2 2
d \alpha
%%---Page 6Subject CT3 (Probability and Mathematical Statistics Core Technical) — September 2006 — Examiners’ Report
\sigma 22
∴ \alpha=
\sigma 1 2 + \sigma 2 2
d 2 MSE
d \alpha 2
(iv)
= 2
\sigma 1 2
\sigma 2
+ 2 2 > 0 ∴ minimum
n
n
The maximum likelihood estimator of μ in the special case with
\sigma 1 2 = \sigma 2 2 = \sigma 2 is
μ ˆ =
=
nX + nX 2
sum of observations
= 1
number of observations
2 n
1
1
X 1 + X 2
2
2
This is the same as W since
\alpha=
9
(i)
\sigma 2 2
\sigma 1 2
+ \sigma 2 2
=
\sigma 2
2
\sigma +\sigma
2
=
1
1
1
⇒ W = X 1 + X 2 .
2
2
2
E [ E ( Y | X )] = \int E [ Y | X = x ] f ( x ) dx
= \int \int yf ( y | x ) dy f ( x ) dx
= \int \int y f ( y | x ) f ( x ) dydx
but f ( y | x ) f ( x ) = f ( x , y ), the joint pdf of X and Y , so
\[E [ E ( Y | X )] = \int \int y f ( x , y ) dxdy = E [ Y ]\]
(ii)
\begin{eqnarray*}
E [ Y ] &=& E [ E ( Y | X )] \\
= E [ X 2 + 1]\\
= V [ X ] + { E [ X ]} 2 + 1 \\
= 1 + 0 + 1 \\
= 2\\
\end{eqnarray*}

Var [ Y ] = Var [ E ( Y | X )] + E [ Var ( Y | X )] = Var [ X 2 + 1] + E [ X 2 + 1]
= Var [ X 2 ] + E [ X 2 ] + 1
but Z = X 2 is χ 1 2 so has variance 2 and expectation 1
Thus Var [ Y ] = 2 + 1 + 1 = 4
%%---Page 7Subject CT3 (Probability and Mathematical Statistics Core Technical) — September 2006 — Examiners’ Report
\newpage
%%--- Question10
(i)
(a)
Mgf of X i is (1 – t / \lambda ) − 4.5 so mgf of
n
∏ ( 1 − t / \lambda )
− 4.5
= ( 1 − t / \lambda )
n
∑ X i
is
i = 1
− 4.5 n
i = 1
n
Hence mgf of 2 \lambda ∑ X i = 2 \lambda nX is ( 1 − 2 \lambda t / \lambda )
− 4.5 n
= ( 1 − 2 t )
− 4.5 n
i = 1
This is the mgf of a χ 2 variable — with 9n degrees of freedom.
(b)
b ⎞
⎛ a
<\lambda<
P ( a < 2 \lambda nX < b ) = 0.95 ⇒ P ⎜
⎟ = 0.95
2 nX ⎠
⎝ 2 nX
where a and b are such that
(
)
(
)
P χ 9 2 n < a = 0.025 and P χ 9 2 n > b = 0.025.
b
⎛ a
so a 95% CI for \lambda is given by ⎜
,
⎝ 2 nX 2 nX
(c)
⎞
⎟ .
⎠
9 n = 90, and from tables of χ 2 with 90df we have a = 65.65, b = 118.1
118.1 ⎞
⎛ 65.65
CI is ⎜
,
⎟ = (1.53 , 2.75).
⎝ 2 × 21.47 2 × 21.47 ⎠
(ii)
(a)
(
L ( \lambda ) ∝ \lambda 4.5 n exp −\lambda ∑ x i
)
so
A ( \lambda ) = ( 4.5 n ) log \lambda − \lambda ∑ x i + constant
⇒
d A
= 4.5 n / \lambda − ∑ x i
d \lambda
d 2 A
Setting
= 4.5 n / \lambda 2 so s . e .( \hat{\lambda}) ≅
(b) −
(c) 95% CI is \hat{\lambda}\pm 1.96 × s . e . \lambda ˆ
d \lambda
2
{
\lambda ˆ
( 4.5 n ) 1/ 2
( ) }
In the case n = 100, \sigmax = 225.3,
Page 8
4.5 n 4.5
d A
=
= 0 ⇒ \hat{\lambda}=
d \lambda
∑ X i X
%%---- Subject CT3 (Probability and Mathematical Statistics Core Technical) — September 2006 — Examiners’ Report
4.5 / 2.253
\hat{\lambda}= 4.5 / 2.253 = 1.9973 and s . e .( \hat{\lambda}) ≅
= 0.0942
( 450 ) 1/ 2
so CI is 1.9973 \pm(1.96 × 0.0942) i.e. (1.81 , 2.18).
