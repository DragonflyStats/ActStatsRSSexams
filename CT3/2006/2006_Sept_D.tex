
\documentclass[a4paper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngpage}

%\usepackage{bigints}
\usepackage{vmargin}

% left top textwidth textheight headheight

% headsep footheight footskip

\setmargins{2.0cm}{2.5cm}{16 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}

\renewcommand{\baselinestretch}{1.3}

\setcounter{MaxMatrixCols}{10}

\begin{document}
\begin{enumerate}


8
Let X 1 denote the mean of a random sample of size n from a normal population with
mean
2
1 ,
and variance
and let X 2 denote the mean of a random sample also of
size n from a normal population with the same mean
two samples are independent.
but with variance
2
2 .
The
Define W as the weighted average of the sample means
W
X 1 (1
) X 2
(i) Show that W is an unbiased estimator of . [1]
(ii) Obtain an expression for the mean square error of W. [2]
(iii) Show that the value of
given by
2
2
2
1
2
2
for which W has minimum mean square error is
,
and verify that the optimum corresponds to a minimum.
9
[3]
(iv) Consider the special case when the variances of the two random samples are
equal to a common value 2 . State (do not derive) the maximum likelihood
estimator of calculated from the combined samples, and compare it with the
estimator obtained in (iii).
[2]
[Total 8]
(i) Show that for continuous random variables X and Y:
E[Y] = E[E(Y|X)].
(ii)
Suppose that a random variable X has a standard normal distribution, and the
conditional distribution of a Poisson random variable Y, given the value of
X = x, has expectation g(x) = x 2 + 1.
Determine E[Y] and Var[Y].
CT3 S2006
[3]
4
[5]
[Total 8]10
Let (X 1 , X 2 ,
, X n ) be a random sample of a gamma(4.5, ) random variable, with
sample mean X .
(i)
(ii)
2
9 n .
(a) Using moment generating functions, show that 2 nX ~
(b) Construct a 95% confidence interval for , based on X and the result
in (i)(a) above.
(c) Evaluate the interval in (i)(b) above in the case for which a random
sample of 10 observations gave a value
x i 21.47
[9]
(a) Show that the maximum likelihood estimator of
is given by
4.5
.
X
(b)
Show that the asymptotic standard error of
4.5n
(c)
1/ 2
is estimated by
.
Construct a 95% confidence interval for based on the asymptotic
distribution of , and evaluate this interval in the case for which a
random sample of 100 observations gave a value
x i 225.3.
[9]
[Total 18]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%8
(i)
E ( W ) = E ( α X 1 + (1 − α ) X 2 )
= α E ( X 1 ) + (1 − α ) E ( X 2 ) = αμ + (1 − α ) μ = μ
Therefore W is unbiased.
(ii)
MSE(W) = var(W) + {bias(W)} 2
W is unbiased
∴ MSE(W) = var(W)
= var( α X 1 + (1 − α ) X 2 )
= α 2 var( X 1 ) + (1 − α ) 2 var( X 2 ) (independent samples)
= α 2
(iii)
σ 1 2
σ 2
+ (1 − α ) 2 2
n
n
σ 2
σ 2
d MSE
= 2 α 1 − 2(1 − α ) 2
d α
n
n
d MSE
= 0 ⇒ ( σ 1 2 + σ 2 2 ) α = σ 2 2
d α
Page 6Subject CT3 (Probability and Mathematical Statistics Core Technical) — September 2006 — Examiners’ Report
σ 22
∴ α=
σ 1 2 + σ 2 2
d 2 MSE
d α 2
(iv)
= 2
σ 1 2
σ 2
+ 2 2 > 0 ∴ minimum
n
n
The maximum likelihood estimator of μ in the special case with
σ 1 2 = σ 2 2 = σ 2 is
μ ˆ =
=
nX + nX 2
sum of observations
= 1
number of observations
2 n
1
1
X 1 + X 2
2
2
This is the same as W since
α=
9
(i)
σ 2 2
σ 1 2
+ σ 2 2
=
σ 2
2
σ +σ
2
=
1
1
1
⇒ W = X 1 + X 2 .
2
2
2
E [ E ( Y | X )] = ∫ E [ Y | X = x ] f ( x ) dx
= ∫ ∫ yf ( y | x ) dy f ( x ) dx
= ∫ ∫ y f ( y | x ) f ( x ) dydx
but f ( y | x ) f ( x ) = f ( x , y ), the joint pdf of X and Y , so
E [ E ( Y | X )] = ∫ ∫ y f ( x , y ) dxdy = E [ Y ]
(ii)
E [ Y ] = E [ E ( Y | X )] = E [ X 2 + 1]
= V [ X ] + { E [ X ]} 2 + 1 = 1 + 0 + 1 = 2
Var [ Y ] = Var [ E ( Y | X )] + E [ Var ( Y | X )] = Var [ X 2 + 1] + E [ X 2 + 1]
= Var [ X 2 ] + E [ X 2 ] + 1
but Z = X 2 is χ 1 2 so has variance 2 and expectation 1
Thus Var [ Y ] = 2 + 1 + 1 = 4
Page 7Subject CT3 (Probability and Mathematical Statistics Core Technical) — September 2006 — Examiners’ Report
10
(i)
(a)
Mgf of X i is (1 – t / λ ) − 4.5 so mgf of
n
∏ ( 1 − t / λ )
− 4.5
= ( 1 − t / λ )
n
∑ X i
is
i = 1
− 4.5 n
i = 1
n
Hence mgf of 2 λ ∑ X i = 2 λ nX is ( 1 − 2 λ t / λ )
− 4.5 n
= ( 1 − 2 t )
− 4.5 n
i = 1
This is the mgf of a χ 2 variable — with 9n degrees of freedom.
(b)
b ⎞
⎛ a
<λ<
P ( a < 2 λ nX < b ) = 0.95 ⇒ P ⎜
⎟ = 0.95
2 nX ⎠
⎝ 2 nX
where a and b are such that
(
)
(
)
P χ 9 2 n < a = 0.025 and P χ 9 2 n > b = 0.025.
b
⎛ a
so a 95% CI for λ is given by ⎜
,
⎝ 2 nX 2 nX
(c)
⎞
⎟ .
⎠
9 n = 90, and from tables of χ 2 with 90df we have a = 65.65, b = 118.1
118.1 ⎞
⎛ 65.65
CI is ⎜
,
⎟ = (1.53 , 2.75).
⎝ 2 × 21.47 2 × 21.47 ⎠
(ii)
(a)
(
L ( λ ) ∝ λ 4.5 n exp −λ ∑ x i
)
so
A ( λ ) = ( 4.5 n ) log λ − λ ∑ x i + constant
⇒
d A
= 4.5 n / λ − ∑ x i
d λ
d 2 A
Setting
= 4.5 n / λ 2 so s . e .( λ ˆ ) ≅
(b) −
(c) 95% CI is λ ˆ ± 1.96 × s . e . λ ˆ
d λ
2
{
λ ˆ
( 4.5 n ) 1/ 2
( ) }
In the case n = 100, Σx = 225.3,
Page 8
4.5 n 4.5
d A
=
= 0 ⇒ λ ˆ =
d λ
∑ X i XSubject CT3 (Probability and Mathematical Statistics Core Technical) — September 2006 — Examiners’ Report
4.5 / 2.253
λ ˆ = 4.5 / 2.253 = 1.9973 and s . e .( λ ˆ ) ≅
= 0.0942
( 450 ) 1/ 2
so CI is 1.9973 ±(1.96 × 0.0942) i.e. (1.81 , 2.18).
